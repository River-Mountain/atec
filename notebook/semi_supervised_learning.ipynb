{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../data/dzh\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', filename='/home/mountain/atec/notebook/log/semi.log', level=logging.INFO)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.semi_supervised import LabelPropagation,LabelSpreading\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled = pd.read_hdf(\"train_labeled.h5\", \"train\")\n",
    "\n",
    "# # 有标签样本和主动学习得到的样本结合起来用\n",
    "# train_pl = pd.read_pickle(\"train_pl\")\n",
    "# train_labeled = pd.concat([train_labeled, train_pl], ignore_index=True)\n",
    "\n",
    "train_unlabeled = pd.read_hdf(\"train_unlabeled.h5\", \"train\")\n",
    "test = pd.read_hdf(\"test.h5\", \"test\")\n",
    "\n",
    "x_train_labeled = np.array(train_labeled)[:,1:]\n",
    "y_train_labeled =  np.array(train_labeled)[:,0].reshape(len(x_train_labeled),1)\n",
    "x_train_unlabeled  = np.array(train_unlabeled)\n",
    "x_test = np.array(test)\n",
    "\n",
    "# 采用直推学习，把要预测的数据放在模型中\n",
    "x_train_unlabeled = np.concatenate((x_train_unlabeled, x_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 128)\n",
      "(29000, 128)\n",
      "(8000, 128)\n"
     ]
    }
   ],
   "source": [
    "print x_train_labeled.shape\n",
    "print x_train_unlabeled.shape\n",
    "print x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主动学习\n",
    "- 模型暂时用xgb，把无标签样本当做预测样本，再根据把部分无标签样本再当做有标签样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载\n",
    "dtrain = xgb.DMatrix(x_train_labeled, label=y_train_labeled)\n",
    "# dtest = xgb.DMatrix(x_train_unlabeled)\n",
    "dtest = xgb.DMatrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation，设置参数，训练模型\n",
    "param_prob = {'max_depth':5, 'eta':0.0, 'tree_method':'gpu_exact', 'eval_metric':'merror', 'objective':'multi:softprob', 'num_class':10}\n",
    "param = {'max_depth':5, 'eta':0.05, 'tree_method':'gpu_exact', 'eval_metric':'merror', 'objective':'multi:softmax', 'num_class':10}\n",
    "\n",
    "num_round = 10\n",
    "\n",
    "# cv_result = xgb.cv(params=param, dtrain=dtrain, num_boost_round=num_round, nfold=10, early_stopping_rounds=10)\n",
    "bst_prob = xgb.train(params=param_prob, dtrain=dtrain, num_boost_round=num_round)\n",
    "bst = xgb.train(params=param, dtrain=dtrain, num_boost_round=num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_prob = bst_prob.predict(dtest)\n",
    "test_predict = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据softmax得到的概率值，设定一个阈值，转换部分无标签数据，变成有标签数据\n",
    "data = pd.concat([pd.Series(test_predict), pd.Series(test_predict_prob.max(axis=1))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_unlabeled_labeled = pd.DataFrame(x_train_unlabeled)[data[1] > 0.3]\n",
    "y_train_unlabeled_labeled = data[data[1] > 0.3][0]\n",
    "train_pl = pd.concat([y_train_unlabeled_labeled, x_train_unlabeled_labeled], axis=1)\n",
    "train_pl.columns = train_labeled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl.to_pickle(\"train_pl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 半监督学习，数据格式转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_unlabeled = -1*np.ones((len(x_train_unlabeled),1))\n",
    "x_train  = np.concatenate((x_train_labeled,x_train_unlabeled),axis=0)\n",
    "y_train = np.concatenate((y_train_labeled,y_train_unlabeled),axis=0).reshape(-1)\n",
    "\n",
    "# 一定要标准化、归一化，别忘了！！\n",
    "x_train = MinMaxScaler().fit_transform(x_train)\n",
    "x_train = Normalizer().fit_transform(x_train)\n",
    "\n",
    "x_test = MinMaxScaler().fit_transform(x_test)\n",
    "x_test = Normalizer().fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归，监督学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(x_train_labeled,y_train_labeled)\n",
    "y_predict = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn图半监督学习，改造源码，打印一些输出\n",
    "- 内存消耗很大，很慢\n",
    "- 结果：用rbf核，速度很慢，计算出来全是同一个类别；用knn核，速度很快，但是效果没有很好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelSpreading(alpha=0.2, gamma=20, kernel='knn', max_iter=30, n_jobs=-1,\n",
       "        n_neighbors=7, tol=0.0001)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LabelSpreading(\"knn\", tol=0.0001, n_jobs=-1)\n",
    "logging.info(\"start!\")\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.transduction_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.transduction_[30000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试一个小样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle 十分之一的样本出来\n",
    "y_x_train = pd.concat([pd.Series(y_train), pd.DataFrame(x_train)], axis=1)\n",
    "y_x_train = y_x_train.sample(frac=0.1).reset_index(drop=True)\n",
    "y_train = np.array(y_x_train.iloc[:, 0])\n",
    "x_train = np.array(y_x_train.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LabelSpreading(tol=0.0001, n_jobs=-1)\n",
    "# clf = LabelPropagation(tol=0.0001, n_jobs=-1)\n",
    "logging.info(\"start!\")\n",
    "clf.fit(x_train, y_train)\n",
    "y_predict = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成式方法的半监督学习\n",
    "- 基于GMM分布假设\n",
    "- 注意PCA降维，降低计算开销\n",
    "- 效果估计也不好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成式方法的半监督学习\n",
    "- 基于GMM分布假设\n",
    "- 注意PCA降维，降低计算开销\n",
    "- 效果估计也不好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存结果及模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([pd.Series(test.index.values, dtype='int32'), pd.Series(y_predict, dtype='int32')], axis=1)\n",
    "res.columns = [\"Id\", \"y\"]\n",
    "res.to_csv(\"result_transduc.csv\", index=False)\n",
    "\n",
    "# with open(\"model_0516\", 'w') as f:\n",
    "#     pickle.dump(obj=clf, file=f)\n",
    "\n",
    "# logging.info(\"end!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn semi supervised learning example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===================================================\n",
    "Label Propagation digits: Demonstrating performance\n",
    "===================================================\n",
    "\n",
    "This example demonstrates the power of semisupervised learning by\n",
    "training a Label Spreading model to classify handwritten digits\n",
    "with sets of very few labels.\n",
    "\n",
    "The handwritten digit dataset has 1797 total points. The model will\n",
    "be trained using all points, but only 30 will be labeled. Results\n",
    "in the form of a confusion matrix and a series of metrics over each\n",
    "class will be very good.\n",
    "\n",
    "At the end, the top 10 most uncertain predictions will be shown.\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Authors: Clay Woolam <clay@woolam.org>\n",
    "# License: BSD\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.semi_supervised import label_propagation\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "rng = np.random.RandomState(0)\n",
    "indices = np.arange(len(digits.data))\n",
    "rng.shuffle(indices)\n",
    "\n",
    "X = digits.data[indices[:330]]\n",
    "y = digits.target[indices[:330]]\n",
    "images = digits.images[indices[:330]]\n",
    "\n",
    "n_total_samples = len(y)\n",
    "n_labeled_points = 30\n",
    "\n",
    "indices = np.arange(n_total_samples)\n",
    "\n",
    "unlabeled_set = indices[n_labeled_points:]\n",
    "\n",
    "# #############################################################################\n",
    "# Shuffle everything around\n",
    "y_train = np.copy(y)\n",
    "y_train[unlabeled_set] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Learn with LabelSpreading\n",
    "lp_model = label_propagation.LabelSpreading(gamma=0.25, max_iter=5)\n",
    "lp_model.fit(X, y_train)\n",
    "predicted_labels = lp_model.transduction_[unlabeled_set]\n",
    "true_labels = y[unlabeled_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, predicted_labels, labels=lp_model.classes_)\n",
    "\n",
    "print(\"Label Spreading model: %d labeled & %d unlabeled points (%d total)\" %\n",
    "      (n_labeled_points, n_total_samples - n_labeled_points, n_total_samples))\n",
    "\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)\n",
    "\n",
    "# #############################################################################\n",
    "# Calculate uncertainty values for each transduced distribution\n",
    "pred_entropies = stats.distributions.entropy(lp_model.label_distributions_.T)\n",
    "\n",
    "# #############################################################################\n",
    "# Pick the top 10 most uncertain labels\n",
    "uncertainty_index = np.argsort(pred_entropies)[-10:]\n",
    "\n",
    "# #############################################################################\n",
    "# Plot\n",
    "f = plt.figure(figsize=(7, 5))\n",
    "for index, image_index in enumerate(uncertainty_index):\n",
    "    image = images[image_index]\n",
    "\n",
    "    sub = f.add_subplot(2, 5, index + 1)\n",
    "    sub.imshow(image, cmap=plt.cm.gray_r)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    sub.set_title('predict: %i\\ntrue: %i' % (\n",
    "        lp_model.transduction_[image_index], y[image_index]))\n",
    "\n",
    "f.suptitle('Learning with small amount of labeled data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
